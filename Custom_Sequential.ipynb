{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LokKaturi/Advance-Applications-of-AI-/blob/main/Custom_Sequential.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76354768",
      "metadata": {
        "id": "76354768"
      },
      "source": [
        "**NOTE: See the Assignments page in the \"Start here\" module for the rubric that will be used to grade labs.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b5a953ff",
      "metadata": {
        "id": "b5a953ff"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "396affc0",
      "metadata": {
        "id": "396affc0"
      },
      "source": [
        "For this lab we will use the Scikit-Learn [breast cancer](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset) toy dataset. It has various attributes of cell nuclei as features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4e280335",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e280335",
        "outputId": "d2278b12-3fac-469f-a9c0-3113e5fa52cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples: 569\tFeatures: 30\n"
          ]
        }
      ],
      "source": [
        "(X, y) = load_breast_cancer(return_X_y=True)\n",
        "m = X.shape[0]\n",
        "n_features = X.shape[1]\n",
        "print(\"Samples: %d\\tFeatures: %d\"%(m,n_features))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc004838",
      "metadata": {
        "id": "dc004838"
      },
      "source": [
        "**1. Use the Scikit-Learn `train_test_split()` function to split X and y into train and test sets, with 80% of the data as the training set, and store in `X_train`, `X_test`, `y_train`, `y_test`.**\n",
        "  - Hint: check out the examples in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
        "  - Hint: look at the arguments `test_size` and `train_size`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ecb691a3",
      "metadata": {
        "id": "ecb691a3"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4005442",
      "metadata": {
        "id": "e4005442"
      },
      "source": [
        "**2. Fit a [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) to just the training input. Use the fit model to scale both the training and testing inputs, storing the scaled data back in `X_train` and `X_test` again.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "faa839c2",
      "metadata": {
        "id": "faa839c2"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "#minmazscaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d61aed64",
      "metadata": {
        "id": "d61aed64"
      },
      "source": [
        "**3. Define a Keras sequential model with two hidden layers, the first with 64 neurons, the second with 32 neurons, and a single output neuron. Use ReLU activation for the two hidden layers and sigmoid for the output layer**\n",
        "- Hint: remember that the input shape must match the number of features we have.\n",
        "- Hint: choose appropriate activation functions for each layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "28acb89d",
      "metadata": {
        "id": "28acb89d"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "model = Sequential() \n",
        "input_layer = Dense(128, input_shape=(30,)); \n",
        "model.add(input_layer) \n",
        "hidden_layer1 = Dense(64, activation='relu'); \n",
        "model.add(hidden_layer1)\n",
        "hidden_layer2 = Dense(32, activation='relu'); \n",
        "model.add(hidden_layer2) \n",
        "output_layer = Dense(1,activation='sigmoid') \n",
        "model.add(output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWYozWFv8_lo",
        "outputId": "3ec9a91f-b903-4fd8-9a8d-618d27834869"
      },
      "id": "fWYozWFv8_lo",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 128)               3968      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,337\n",
            "Trainable params: 14,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "704a3149",
      "metadata": {
        "id": "704a3149"
      },
      "source": [
        "**4. Compile the model with binary cross-entropy loss, accuracy for metrics, and a Stochastic Gradient Descent optimizer.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f81f3d59",
      "metadata": {
        "id": "f81f3d59"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "model.compile(optimizer='sgd',\n",
        "          loss='binary_crossentropy',\n",
        "          metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e9d9681",
      "metadata": {
        "id": "3e9d9681"
      },
      "source": [
        "**5. Fit the model to the training data, using 16 epochs and a batch size of 8.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "11d37ada",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11d37ada",
        "outputId": "71d5727d-8b6c-4eee-b5f0-42311bf0dbb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n",
            "57/57 [==============================] - 2s 8ms/step - loss: 0.6874 - accuracy: 0.6154 - val_loss: 0.6648 - val_accuracy: 0.6316\n",
            "Epoch 2/16\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.6511 - accuracy: 0.6637 - val_loss: 0.6300 - val_accuracy: 0.6930\n",
            "Epoch 3/16\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.6179 - accuracy: 0.7473 - val_loss: 0.5935 - val_accuracy: 0.7719\n",
            "Epoch 4/16\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.5817 - accuracy: 0.7824 - val_loss: 0.5534 - val_accuracy: 0.8596\n",
            "Epoch 5/16\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.8571 - val_loss: 0.5075 - val_accuracy: 0.9035\n",
            "Epoch 6/16\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.8835 - val_loss: 0.4556 - val_accuracy: 0.9211\n",
            "Epoch 7/16\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.9077 - val_loss: 0.3995 - val_accuracy: 0.9386\n",
            "Epoch 8/16\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.9121 - val_loss: 0.3444 - val_accuracy: 0.9474\n",
            "Epoch 9/16\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.9275 - val_loss: 0.2975 - val_accuracy: 0.9386\n",
            "Epoch 10/16\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2972 - accuracy: 0.9165 - val_loss: 0.2541 - val_accuracy: 0.9561\n",
            "Epoch 11/16\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2622 - accuracy: 0.9275 - val_loss: 0.2217 - val_accuracy: 0.9474\n",
            "Epoch 12/16\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2330 - accuracy: 0.9319 - val_loss: 0.2013 - val_accuracy: 0.9737\n",
            "Epoch 13/16\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9363 - val_loss: 0.1764 - val_accuracy: 0.9474\n",
            "Epoch 14/16\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1971 - accuracy: 0.9407 - val_loss: 0.1590 - val_accuracy: 0.9474\n",
            "Epoch 15/16\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1823 - accuracy: 0.9407 - val_loss: 0.1466 - val_accuracy: 0.9561\n",
            "Epoch 16/16\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.1656 - accuracy: 0.9451 - val_loss: 0.1472 - val_accuracy: 0.9737\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "history = model.fit(X_train, y_train, \n",
        "   batch_size = 8, epochs =16 , verbose = 1, validation_data = (X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de82e711",
      "metadata": {
        "id": "de82e711"
      },
      "source": [
        "## Torch (optional tutorial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d31844",
      "metadata": {
        "id": "b3d31844"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bb49f5a",
      "metadata": {
        "id": "0bb49f5a"
      },
      "source": [
        "Create train/test split and batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd477ae4",
      "metadata": {
        "id": "cd477ae4"
      },
      "outputs": [],
      "source": [
        "class dataset(Dataset):\n",
        "  def __init__(self,x,y):\n",
        "    self.x = torch.tensor(x,dtype=torch.float32)\n",
        "    self.y = torch.tensor(y,dtype=torch.float32)\n",
        "    self.length = self.x.shape[0]\n",
        " \n",
        "  def __getitem__(self,idx):\n",
        "    return self.x[idx],self.y[idx]\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "ds_train = dataset(X_train, y_train)\n",
        "dl_train = DataLoader(ds_train, batch_size=16, shuffle=True)\n",
        "\n",
        "ds_test = dataset(X_test, y_test)\n",
        "dl_test = DataLoader(ds_test, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd58397d",
      "metadata": {
        "id": "fd58397d"
      },
      "source": [
        "### Define the model\n",
        "\n",
        "In the `Week1Network` constructor, we'll create `self.layer1` and `self.layer2` as linear layers. In `forward()`, we'll pass values from layer1 to this layer2, then to a ReLU activation, and store in `x`. Note that when defining a layer, `in_features` must match the `out_features` of the previous layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61883c5d",
      "metadata": {
        "id": "61883c5d"
      },
      "outputs": [],
      "source": [
        "class Week1Network(torch.nn.Module):\n",
        "    def __init__(self, n_features):\n",
        "        super(Week1Network, self).__init__()\n",
        "        self.layer1 = torch.nn.Linear(n_features, 64)\n",
        "        self.layer2 = torch.nn.Linear(64, 32)\n",
        "        self.layer_out = torch.nn.Linear(32,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.layer_out(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52c7bd96",
      "metadata": {
        "id": "52c7bd96"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68f77cc9",
      "metadata": {
        "id": "68f77cc9"
      },
      "source": [
        "We'll create an instance of our `Week1Network` class, and store in `model`, then create a Torch SGD optimizer object with a learning rate of 0.01, and store in `opt`. Finally, we'll create a Torch loss function object of the appropriate type for our binary classification problem, and store in `loss_fn`. Note that the initializer takes the number of features as a parameter. This must match the number of features in the breast cancer dataset that is loaded above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "496b59f3",
      "metadata": {
        "id": "496b59f3"
      },
      "outputs": [],
      "source": [
        "model = Week1Network(n_features)\n",
        "opt = torch.optim.SGD(model.parameters(),lr=0.1)\n",
        "loss_fn = torch.nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "643f47ed",
      "metadata": {
        "id": "643f47ed",
        "outputId": "65519d10-52cd-4c4a-fc46-86bb415e4bba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch:  1 loss: 0.607096\n",
            "epoch:  2 loss: 0.602971\n",
            "epoch:  3 loss: 0.431558\n",
            "epoch:  4 loss: 0.205088\n",
            "epoch:  5 loss: 0.472856\n",
            "epoch:  6 loss: 0.172466\n",
            "epoch:  7 loss: 0.187797\n",
            "epoch:  8 loss: 0.207219\n",
            "epoch:  9 loss: 0.384883\n",
            "epoch: 10 loss: 0.103833\n",
            "epoch: 11 loss: 0.798564\n",
            "epoch: 12 loss: 0.174365\n",
            "epoch: 13 loss: 0.105504\n",
            "epoch: 14 loss: 0.010925\n",
            "epoch: 15 loss: 0.046219\n",
            "epoch: 16 loss: 0.173096\n"
          ]
        }
      ],
      "source": [
        "size = len(dl_train.dataset)\n",
        "\n",
        "for i in range(16): # epochs\n",
        "    for batch, (X_batch, y_batch) in enumerate(dl_train):\n",
        "        pred = model(X_batch)\n",
        "        loss = loss_fn(pred, y_batch.reshape(-1,1))\n",
        "\n",
        "        # Backpropagation\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "    print(f\"epoch: {i+1:2d} loss: {loss:>7f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8fb2f54",
      "metadata": {
        "id": "b8fb2f54"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8281fc87",
      "metadata": {
        "id": "8281fc87",
        "outputId": "1630ba15-37a7-4cd6-fc00-1c8ef6772299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error: \n",
            " Accuracy: 93.0%, Avg loss: 0.121503 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "num_batches = len(dl_test)\n",
        "test_loss, correct = 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in dl_test:\n",
        "        pred = model(X_batch)\n",
        "        test_loss += loss_fn(pred, y_batch.reshape(-1,1))\n",
        "        correct += (pred.reshape(-1).round() == y_batch).sum().item()\n",
        "\n",
        "test_loss /= num_batches\n",
        "correct /= len(dl_test.dataset)\n",
        "print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98929f17",
      "metadata": {
        "id": "98929f17"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}